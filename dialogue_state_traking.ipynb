{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "ner_pipe = pipeline(\"token-classification\", model=\"NguyenMinh03082004/velectra_fine_tune_for_laptop_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {\n",
    "    \"LABEL_0\": 'B-ai_task',\n",
    "    \"LABEL_1\": 'B-basic_task',\n",
    "    \"LABEL_2\": 'B-battery',\n",
    "    \"LABEL_3\": 'B-battery_capacity',\n",
    "    \"LABEL_4\": 'B-brand',\n",
    "    \"LABEL_5\": 'B-cheap_option',\n",
    "    \"LABEL_6\": 'B-cpu',\n",
    "    \"LABEL_7\": 'B-designer',\n",
    "    \"LABEL_8\": 'B-developer',\n",
    "    \"LABEL_9\": 'B-game_task',\n",
    "    \"LABEL_10\": 'B-gpu',\n",
    "    \"LABEL_11\": 'B-high_fresh_rate',\n",
    "    \"LABEL_12\": 'B-high_performance',\n",
    "    \"LABEL_13\": 'B-light_weight',\n",
    "    \"LABEL_14\": 'B-long_battery',\n",
    "    \"LABEL_15\": 'B-os',\n",
    "    \"LABEL_16\": 'B-price_range',\n",
    "    \"LABEL_17\": 'B-prod_name',\n",
    "    \"LABEL_18\": 'B-quick_charge',\n",
    "    \"LABEL_19\": 'B-ram',\n",
    "    \"LABEL_20\": 'B-screen_fresh_rate',\n",
    "    \"LABEL_21\": 'B-screen_quality',\n",
    "    \"LABEL_22\": 'B-screen_resolution',\n",
    "    \"LABEL_23\": 'B-screen_size',\n",
    "    \"LABEL_24\": 'B-weight',\n",
    "    \"LABEL_25\": 'I-ai_task',\n",
    "    \"LABEL_26\": 'I-basic_task',\n",
    "    \"LABEL_27\": 'I-cheap_option',\n",
    "    \"LABEL_28\": 'I-cpu',\n",
    "    \"LABEL_29\": 'I-designer',\n",
    "    \"LABEL_30\": 'I-developer',\n",
    "    \"LABEL_31\": 'I-game_task',\n",
    "    \"LABEL_32\": 'I-gpu',\n",
    "    \"LABEL_33\": 'I-high_fresh_rate',\n",
    "    \"LABEL_34\": 'I-high_performance',\n",
    "    \"LABEL_35\": 'I-light_weight',\n",
    "    \"LABEL_36\": 'I-long_battery',\n",
    "    \"LABEL_37\": 'I-os',\n",
    "    \"LABEL_38\": 'I-price_range',\n",
    "    \"LABEL_39\": 'I-prod_name',\n",
    "    \"LABEL_40\": 'I-quick_charge',\n",
    "    \"LABEL_41\": 'I-screen_fresh_rate',\n",
    "    \"LABEL_42\": 'I-screen_quality',\n",
    "    \"LABEL_43\": 'I-screen_resolution',\n",
    "    \"LABEL_44\": 'O'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tokens_and_labels(tokens, predicted_labels):\n",
    "    combined_tokens = []\n",
    "    combined_labels = []\n",
    "    current_token = \"\"\n",
    "    current_label = \"\"\n",
    "\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if token.startswith(\"##\"):\n",
    "            current_token += token[2:]  # Append subword (remove '##')\n",
    "        elif token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:  # ignored token.\n",
    "            continue\n",
    "        elif current_token and (token.startswith(\".\") or (current_token.endswith(\".\") and token.isdigit())): \n",
    "            current_token += token\n",
    "        else:\n",
    "            if current_token:  # Add the last token and label\n",
    "                combined_tokens.append(current_token)\n",
    "                combined_labels.append(current_label)\n",
    "            current_token = token\n",
    "            current_label = label\n",
    "\n",
    "    # Finalize the last token\n",
    "    if current_token:\n",
    "        combined_tokens.append(current_token)\n",
    "        combined_labels.append(current_label)\n",
    "\n",
    "    return combined_tokens, combined_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_entities(combined_tokens, combined_labels):\n",
    "    entities = []\n",
    "    current_entity = \"\"\n",
    "    current_label = \"\"\n",
    "\n",
    "    for token, label in zip(combined_tokens, combined_labels):\n",
    "        if label.startswith('B-'):  # beginning of new entity\n",
    "            if current_entity:  # if current entity != null => end old entity\n",
    "                entities.append((current_entity.strip(), current_label))\n",
    "            current_entity = token  # start new entity\n",
    "            current_label = label[2:]  # remove the B-, keep only entity\n",
    "        elif label.startswith('I-') and current_entity:  # Continuation of the current entity\n",
    "            current_entity += \" \" + token  # Append token to the current entity\n",
    "        else:  # End of the current entity\n",
    "            if current_entity:  # Save the entity if it exists\n",
    "                entities.append((current_entity.strip(), current_label))\n",
    "                current_entity = \"\"  # Reset for next entity\n",
    "                current_label = \"\"\n",
    "\n",
    "    # Finalize any remaining entity\n",
    "    if current_entity:\n",
    "        entities.append((current_entity.strip(), current_label))\n",
    "\n",
    "    # Merging logic for combined product names\n",
    "    merged_entities = []\n",
    "    i = 0\n",
    "    while i < len(entities):\n",
    "        entity, label = entities[i]\n",
    "\n",
    "        # case for updating product name = brand + product name\n",
    "        if label == 'brand':\n",
    "            if (i + 1 < len(entities) and entities[i + 1][1] == 'prod_name'):\n",
    "                entity += \" \" + entities[i + 1][0]  # Merge the names\n",
    "                label = 'prod_name'  # change label to prod_name\n",
    "                i += 1  # skip the next entity \n",
    "\n",
    "        merged_entities.append((entity.strip(), label))\n",
    "        i += 1\n",
    "\n",
    "    return merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, MT5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MT5Model, AutoConfig\n",
    "\n",
    "class MT5EncoderForIntentRecognition(torch.nn.Module):\n",
    "    def __init__(self, encoder, num_labels, tfidf_dim):\n",
    "        super(MT5EncoderForIntentRecognition, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.tfidf_dense = torch.nn.Linear(tfidf_dim, encoder.config.d_model)\n",
    "        self.classifier = torch.nn.Linear(encoder.config.d_model * 2, num_labels)  # Combine mT5 + TF-IDF\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_path, num_labels, tfidf_dim):\n",
    "        config = AutoConfig.from_pretrained(model_path)\n",
    "        encoder = MT5Model.from_pretrained(model_path).encoder\n",
    "        model = cls(encoder, num_labels, tfidf_dim)\n",
    "        state_dict = torch.load(f\"{model_path}/pytorch_model.bin\", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "        # Load the encoder state_dict\n",
    "        model.encoder.load_state_dict(state_dict['encoder_state_dict'], strict=False)\n",
    "        model.tfidf_dense.load_state_dict(state_dict['tfidf_dense_state_dict'], strict=False)\n",
    "        model.classifier.load_state_dict(state_dict['classifier_state_dict'], strict=False)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, tfidf=None, labels=None):\n",
    "        # mT5 encoding\n",
    "        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = encoder_outputs.last_hidden_state\n",
    "        pooled_output = sequence_output[:, 0, :]  # CLS token embedding\n",
    "\n",
    "        # TF-IDF encoding\n",
    "        tfidf_output = self.tfidf_dense(tfidf)\n",
    "        tfidf_output = self.dropout(tfidf_output)\n",
    "\n",
    "        # Combine mT5 and TF-IDF features\n",
    "        combined_output = torch.cat([pooled_output, tfidf_output], dim=1)\n",
    "        logits = self.classifier(combined_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits} if loss is not None else {\"logits\": logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './mt5_encoder_intent_for_laptop_conversation_ver4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of MT5Model were not initialized from the model checkpoint at ./mt5_encoder_intent_for_laptop_conversation_ver4 and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.final_layer_norm.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.layer_norm.weight', 'encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.0.layer.1.layer_norm.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.layer_norm.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.1.layer_norm.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.0.layer_norm.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.1.layer_norm.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.layer_norm.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.1.layer_norm.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.layer_norm.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.1.layer_norm.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.layer_norm.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.1.layer_norm.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.layer_norm.weight', 'encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.6.layer.1.DenseReluDense.wo.weight', 'encoder.block.6.layer.1.layer_norm.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.layer_norm.weight', 'encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'encoder.block.7.layer.1.DenseReluDense.wo.weight', 'encoder.block.7.layer.1.layer_norm.weight', 'encoder.embed_tokens.weight', 'encoder.final_layer_norm.weight', 'shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_25116\\2488426324.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{model_path}/pytorch_model.bin\", map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MT5EncoderForIntentRecognition(\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (tfidf_dense): Linear(in_features=922, out_features=512, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_intent = AutoTokenizer.from_pretrained(model_path)\n",
    "model_intent = MT5EncoderForIntentRecognition.from_pretrained(model_path, num_labels=14, tfidf_dim=922)\n",
    "device = torch.device('cpu')\n",
    "model_intent.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_label = {0: 'Change Decision', \n",
    "                1: 'Comparison Inquiry', \n",
    "                2: 'Delivery Options', \n",
    "                3: 'Feature Confirmation', \n",
    "                4: 'Find Similar', \n",
    "                5: 'Interest Confirmation', \n",
    "                6: 'Payment Options', \n",
    "                7: 'Price Inquiry', \n",
    "                8: 'Product Availability', \n",
    "                9: 'Purchase Decision', \n",
    "                10: 'Return Policy Inquiry', \n",
    "                11: 'Specific Need', \n",
    "                12: 'Thank You/Closing', \n",
    "                13: 'Warranty Inquiry'}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def predict_intent(model, tokenizer, sentence, vectorizer):\n",
    "    #tokenize input\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=70)\n",
    "\n",
    "    # calculate tf-idf\n",
    "    tfidf_vector = vectorizer.transform([sentence]).toarray()\n",
    "    tfidf_tensor = torch.tensor(tfidf_vector, dtype=torch.float32)\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    tfidf_tensor = tfidf_tensor.to(device)\n",
    "\n",
    "    inputs[\"tfidf\"] = tfidf_tensor\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs[\"logits\"]\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    return num_to_label[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner(text, ner_pipe, id_to_label):\n",
    "    ner_results = ner_pipe(text)\n",
    "    tokens = [result['word'] for result in ner_results]\n",
    "    labels = [id_to_label[result['entity']] for result in ner_results]\n",
    "    combined_tokens, combined_labels = combine_tokens_and_labels(tokens, labels)\n",
    "    entities = bio_to_entities(combined_tokens, combined_labels)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = {\n",
    "    \"prod_name\": None,\n",
    "    \"brand\": None, \n",
    "    \"cpu\": None, \n",
    "    \"gpu\": None,\n",
    "    \"ram\": None, #\n",
    "    \"battery\": None, #\n",
    "    \"price_range\": None,\n",
    "    \"screen_size\": None,\n",
    "    \"screen_resolution\": None,\n",
    "    \"screen_fresh_rate\": None, #\n",
    "    \"os\": None, \n",
    "    \"battery_capacity\": None,\n",
    "    \"weight\": None, #\n",
    "    \"cpu_score\": None, # it will not be printed, used for evaluating\n",
    "    \"gpu_score\": None, # used for evaluating\n",
    "    \"screen_resolution_score\": None, # used to evaluate\n",
    "    \"evaluate_score\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_state = {\n",
    "    \"intent\": None,\n",
    "    \"entities_in_conversation\": {\n",
    "        \"prod_name\": {\"values\": [], \"selected\": None},\n",
    "        \"brand\": {\"values\": [], \"selected\": None},\n",
    "        \"cpu\": {\"values\": [], \"selected\": None},\n",
    "        \"gpu\": {\"values\": [], \"selected\": None},\n",
    "        \"ram\": {\"values\": [], \"selected\": None},\n",
    "        \"battery\": {\"values\": [], \"selected\": None},\n",
    "        \"price_range\": {\"values\": [], \"selected\": None},\n",
    "        \"screen_size\": {\"values\": [], \"selected\": None},    \n",
    "        \"screen_resolution\": {\"values\": [], \"selected\": None},\n",
    "        \"screen_fresh_rate\": {\"values\": [], \"selected\": None},\n",
    "        \"os\": {\"values\": [], \"selected\": None},\n",
    "        \"battery_capacity\": {\"values\": [], \"selected\": None},\n",
    "        \"weight\": {\"values\": [], \"selected\": None}\n",
    "    },\n",
    "    \"entities_for_specific_need\": {\n",
    "        \"high_performance\": False,\n",
    "        \"light_weight\": False,\n",
    "        \"long_battery\": False,\n",
    "        \"quick_charge\": False,\n",
    "        \"high_fresh_rate\": False,\n",
    "        \"screen_quality\": False,\n",
    "        \"cheap_option\": False,\n",
    "        \"designer\": False,\n",
    "        \"developer\": False,\n",
    "        \"game_task\": False,\n",
    "        \"ai_task\": False,\n",
    "        \"basic_task\": False\n",
    "    },\n",
    "    \"product_in_current_message\": [], # it will use to store a temporary product (as a response of the current question of customer) \n",
    "    \"product_in_conversation\": [], # store fully information of products that existed conversation. To easily serach the product that user chosse to buy at the end of conversation\n",
    "    \"positional_product\": -10\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_trieu_to_number(text):\n",
    "    # find all numbers followed by \"trieu\" (case insensitive) in the text\n",
    "    matches = re.findall(r'(\\d+)\\s*trieu', text, re.IGNORECASE)\n",
    "    \n",
    "    # replace with the numeric equivalent\n",
    "    for match in matches:\n",
    "        number_in_million = int(match) * 1000000\n",
    "        text = re.sub(rf'{match}\\s*trieu', str(number_in_million), text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def normalize(product):\n",
    "\n",
    "    # Normalizing individual attributes with checks for None values\n",
    "    normalize_ram_point = (\n",
    "        10 / (1 + math.exp(-0.07 * (product['ram'] - 8)))\n",
    "        if product.get('ram') is not None else 0\n",
    "    )\n",
    "\n",
    "    normalize_screen_fresh_rate = (\n",
    "        10 / (1 + math.exp(-0.04 * (product.get('screen_fresh_rate', 60) - 96.22)))\n",
    "        if product.get('screen_fresh_rate') is not None else 8  # Default to 60 Hz\n",
    "    )\n",
    "\n",
    "    normalize_battery = (\n",
    "        10 / (1 + math.exp(-1.38 * (product.get('battery', 3) - 3)))\n",
    "        if product.get('battery') is not None else 0\n",
    "    )\n",
    "\n",
    "    # Weight normalization with ranges, handling None by defaulting to the lowest score (6)\n",
    "    if product.get('weight') is not None:\n",
    "        if product['weight'] <= 1.4:\n",
    "            normalize_weight = 10\n",
    "        elif product['weight'] <= 2:\n",
    "            normalize_weight = 8\n",
    "        else:\n",
    "            normalize_weight = 6\n",
    "    else:\n",
    "        normalize_weight = 6  # Default for None case\n",
    "\n",
    "    normalize_battery_capacity = (\n",
    "        10 / (1 + math.exp(-0.02 * (product.get('battery_capacity', 90) - 90)))\n",
    "        if product.get('battery_capacity') is not None else 0\n",
    "    )\n",
    "\n",
    "    normalize_screen_size = (\n",
    "        10 / (1 + math.exp(-0.98 * (product.get('screen_size', 13) - 13)))\n",
    "        if product.get('screen_size') is not None else 5\n",
    "    )\n",
    "    return {\n",
    "        \"cpu\": float(product['cpu_score']),\n",
    "        \"gpu\": float(product['gpu_score']),\n",
    "        \"screen_resolution\": float(product['screen_resolution_score']),\n",
    "        \"screen_fresh_rate\": normalize_screen_fresh_rate,\n",
    "        \"battery\": normalize_battery,\n",
    "        \"weight\": normalize_weight,\n",
    "        \"battery_capacity\": normalize_battery_capacity,\n",
    "        \"screen_size\": normalize_screen_size,\n",
    "        \"ram\": normalize_ram_point\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = { # evaluate the importance based on the specific need of user\n",
    "    \"cpu\": 0.0,\n",
    "    \"gpu\": 0.0,\n",
    "    \"screen_resolution\": 0.0,\n",
    "    \"screen_fresh_rate\": 0.0, \n",
    "    \"battery\": 0.0,\n",
    "    \"weight\": 0.0,\n",
    "    \"battery_capacity\": 0.0,\n",
    "    \"screen_size\": 0.0,\n",
    "    \"ram\": 0.0\n",
    "}\n",
    "def updateWeight(dialogue_state):\n",
    "    user_needs = dialogue_state['entities_for_specific_need']\n",
    "    number_of_intent = sum(user_needs.values()) # \n",
    "    for label, value in user_needs.items():\n",
    "        if value:\n",
    "            if label == 'high_performance':\n",
    "                weights['cpu'] += 0.35\n",
    "                weights['gpu'] += 0.35\n",
    "                weights['ram'] += 0.3\n",
    "            if label == 'light_weight':\n",
    "                weights['weight'] += 1.0\n",
    "            if label == 'long_battery':\n",
    "                weights['long_battery'] += 1.0\n",
    "            if label == 'quick_charge':\n",
    "                weights['battery_capacity'] += 1.0\n",
    "            if label == 'high_fresh_rate':\n",
    "                weights['screen_fresh_rate'] += 1.0\n",
    "            if label == 'screen_quality':\n",
    "                weights['screen_resolution'] += 0.5\n",
    "                weights['screen_size'] += 0.3\n",
    "                weights['screen_fresh_rate'] += 0.2\n",
    "            if label == 'designer':\n",
    "                weights['screen_resolution'] += 0.7\n",
    "                weights['screen_size'] += 0.2\n",
    "                weights['screen_fresh_rate'] += 0.1\n",
    "            if label == 'developer':\n",
    "                weights['cpu'] += 0.6\n",
    "                weights['ram'] += 0.25\n",
    "                weights['gpu'] += 0.15\n",
    "            if label == 'game_task':\n",
    "                weights['cpu'] += 0.25\n",
    "                weights['gpu'] += 0.45\n",
    "                weights['screen_fresh_rate']+= 0.15\n",
    "                weights['ram']+= 0.15\n",
    "            if label == 'ai_task':\n",
    "                weights['cpu'] += 0.15\n",
    "                weights['gpu'] += 0.6\n",
    "                weights['ram'] += 0.25\n",
    "            if label == 'basic_task': # focus on weight, battery, screen_resolution\n",
    "                weights['cpu'] += 0.1\n",
    "                weights['gpu'] += 0.1\n",
    "                weights['ram'] += 0.2\n",
    "                weights['battery'] += 0.2\n",
    "                weights['weight'] += 0.2\n",
    "                weights['screen_resolution']+= 0.2\n",
    "    #print(weights)\n",
    "    #print(number_of_intent)\n",
    "    if number_of_intent > 1:\n",
    "        for label in weights:\n",
    "            weights[label] = weights[label] / number_of_intent\n",
    "    #print(weights)\n",
    "def evaluate(dialogue_state, product):\n",
    "    cur_point = 0.0\n",
    "    # formula = sum(weights['type'] * product['type'])\n",
    "    user_needs = dialogue_state['entities_for_specific_need']\n",
    "    normalize_product = normalize(product)\n",
    "    for label in normalize_product:\n",
    "        cur_point += weights[label] * normalize_product[label]             \n",
    "    return cur_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_name\n",
      "brand\n",
      "cpu\n",
      "gpu\n",
      "ram\n",
      "battery\n",
      "price_range\n",
      "screen_size\n",
      "screen_resolution\n",
      "screen_fresh_rate\n",
      "os\n",
      "battery_capacity\n",
      "weight\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "prods_entities = dialogue_state['entities_in_conversation']\n",
    "for label, details in prods_entities.items():\n",
    "    print(label)\n",
    "print(len(prods_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_positional_phrases_vietnamese(text):\n",
    "    positional_keywords = {\n",
    "        \"đầu tiên\": 0,\n",
    "        \"thứ nhất\": 0,\n",
    "        \"đầu\": 0,\n",
    "        \"thứ hai\": 1,\n",
    "        \"thứ ba\": 2,\n",
    "        \"cuối\": -1,\n",
    "        \"cuối cùng\": -1,\n",
    "        \"sau cùng\": -1,\n",
    "        \"vừa được\": -1,\n",
    "        \"mới được\": -1,\n",
    "        \"vừa rồi\": -1\n",
    "    }\n",
    "\n",
    "    regex = r'\\b(đầu tiên|thứ nhất|đầu|thứ hai|thứ ba|cuối cùng|sau cùng|cuối|vừa được|mới được|vừa rồi)\\b'\n",
    "    match = re.search(regex, text.lower(), re.UNICODE)\n",
    "\n",
    "    if match:\n",
    "        matched_word = match.group(0)\n",
    "        position = positional_keywords[matched_word]\n",
    "        #print(matched_word)\n",
    "        return position\n",
    "    else:\n",
    "        return -10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_purchase(dialogue_state):\n",
    "    # get label and specific value to search product in conversation that suit with user's requirement\n",
    "    chosen_map = {}\n",
    "    prods_entities = dialogue_state['entities_in_conversation']\n",
    "    for label, values in prods_entities.items():\n",
    "        if values['selected']: # if exists values['selected']\n",
    "            chosen_map[label] = values['selected'] # assign value\n",
    "    return chosen_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProduct(product_chosen, dialogue_state):\n",
    "    product = []\n",
    "    list_product = dialogue_state['product_in_conversation']\n",
    "    #print(list_product)\n",
    "    for laptop in list_product:\n",
    "        is_match = True\n",
    "        for label, value in product_chosen.items():\n",
    "            if label not in laptop:\n",
    "                is_match = False\n",
    "                break\n",
    "            if label == \"prod_name\":\n",
    "                if str(value).lower() not in str(laptop[label]).lower():\n",
    "                    is_match = False\n",
    "                    break\n",
    "            elif label == \"price_range\":\n",
    "                if isinstance(value, (list, tuple)) and len(value) == 2:\n",
    "                    if not (value[0] <= laptop[label] <= value[1]):\n",
    "                        is_match = False\n",
    "                        break\n",
    "                elif laptop[label] > value:\n",
    "                    is_match = False\n",
    "                    break\n",
    "            else:\n",
    "                if str(laptop[label]).lower() != str(value).lower():\n",
    "                    is_match = False\n",
    "                    break\n",
    "        if is_match:\n",
    "            #print(laptop)\n",
    "            product.append(laptop)\n",
    "    if not product:  # If no matches, return all products\n",
    "        for prod in list_product:\n",
    "            product.append(prod)\n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductFromFilter(products, positional):\n",
    "    if positional == -10: # no information about position\n",
    "        return products[0]\n",
    "    return products[positional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_sql(dialogue_state):\n",
    "    base_sql_query = \"\"\"\n",
    "    SELECT laptop.id, brand, prod_name, ram, cpu, gpu, screen_resolution, \n",
    "           cpu_info.score AS cpu_score, gpu_info.score AS gpu_score, \n",
    "           screen_resolution_info.score AS screen_score, battery, price_range, \n",
    "           screen_size, screen_fresh_rate, os, battery_capacity, weight \n",
    "    FROM laptop \n",
    "    JOIN cpu_info USING (cpu_id) \n",
    "    JOIN gpu_info USING (gpu_id) \n",
    "    JOIN screen_resolution_info USING (screen_id)\n",
    "    \"\"\"\n",
    "    \n",
    "    needs = dialogue_state['intent']\n",
    "    filter_conditions = []\n",
    "    filter_sql = \"\"\n",
    "    \n",
    "    # Only apply specific needs if the intent matches \"Specific Need\"\n",
    "    if needs in ['Specific Need', 'Comparison Inquiry']:\n",
    "        prods_entities = dialogue_state['entities_in_conversation']\n",
    "        for label, details in prods_entities.items():\n",
    "            sub_conditions = []\n",
    "            if details['values']:\n",
    "                if label in ['prod_name', 'brand', 'screen_resolution', 'os', 'cpu', 'gpu']:\n",
    "                    for value in details['values']:\n",
    "                        if label == 'screen_resolution':\n",
    "                            sub_conditions.append(f\"LOWER({label}) = '{value}'\")\n",
    "                        else: \n",
    "                            sub_conditions.append(f\"LOWER({label}) LIKE '%{value}%'\")\n",
    "                    if sub_conditions:\n",
    "                        filter_conditions.append(f\"({' OR '.join(sub_conditions)})\")\n",
    "\n",
    "                elif label in ['ram', 'screen_size', 'battery_capacity', 'weight', 'screen_fresh_rate', 'price_range']:\n",
    "                    if len(details['values']) >= 2:\n",
    "                        min_val, max_val = min(details['values']), max(details['values'])\n",
    "                        #print(min_val, max_val)\n",
    "                        sub_conditions.append(f\"{label} BETWEEN {min_val} AND {max_val}\")\n",
    "                    else:\n",
    "                        if label in ['weight', 'price_range']:\n",
    "                            sub_conditions.append(f\"{label} <= {details['values'][0]}\")\n",
    "                        else:\n",
    "                            sub_conditions.append(f\"{label} >= {details['values'][0]}\")\n",
    "                    if sub_conditions:\n",
    "                        filter_conditions.append(f\"({' OR '.join(sub_conditions)})\")\n",
    "    \n",
    "        where_clause = \" AND \".join(filter_conditions)\n",
    "        if where_clause:\n",
    "            filter_sql = base_sql_query +  \" WHERE \" + where_clause\n",
    "        else: filter_sql = base_sql_query\n",
    "    elif needs in ['Change Decision', 'Product Availability', 'Price Inquiry', 'Interest Confirmation']: # it can be existed selected\n",
    "        prods_entities = dialogue_state['entities_in_conversation']\n",
    "        for label, details in prods_entities.items():\n",
    "            if details['selected']: # exist selected => don't care about the previous entities in array\n",
    "                if label in ['prod_name', 'brand', 'cpu', 'gpu', 'screen_resolution', 'os']:\n",
    "                    if label == 'screen_resolution':\n",
    "                        filter_conditions.append(f\"lower({label}) = '{details['selected']}'\")\n",
    "                    else:    \n",
    "                        filter_conditions.append(f\"lower({label}) LIKE '%{details['selected']}%'\")\n",
    "                else:\n",
    "                    if label not in ['price_range', 'weight']:\n",
    "                        filter_conditions.append(f\"{label} = {details['selected']}\")\n",
    "                    else:\n",
    "                        filter_conditions.append(f\"{label}  <= {details['selected']}\")\n",
    "            else:\n",
    "                if details['values']:\n",
    "                    sub_conditions = []\n",
    "                    if label in ['prod_name', 'brand', 'screen_resolution', 'os', 'cpu', 'gpu']:\n",
    "                        for entity in details['values']:\n",
    "                            if label in ['screen_resolution', 'brand']:\n",
    "                                sub_conditions.append(f\"lower({label}) = '{entity}'\")\n",
    "                            else:\n",
    "                                sub_conditions.append(f\"lower({label}) LIKE '%{entity}%'\")\n",
    "                    else:\n",
    "                        if len(details['values']) >= 2: # normalize that we will search in range between minimum and maximum\n",
    "                            min_val, max_val = min(details['values']), max(details['values'])\n",
    "                            sub_conditions.append(f\"{label} BETWEEN {min_val} AND {max_val}\")\n",
    "                        else:\n",
    "                            if label in ['ram', 'screen_resolution', 'screen_size']:\n",
    "                                filter_conditions.append(f\"{label} = {details['values'][0]}\")\n",
    "                            elif label in ['price_range', 'weight']:\n",
    "                                filter_conditions.append(f\"{label}  <= {details['values'][0]}\")\n",
    "                            else:\n",
    "                                filter_conditions.append(f\"{label} >= {details['values'][0]}\")\n",
    "                    if sub_conditions:\n",
    "                            filter_conditions.append(f\"({' OR '.join(sub_conditions)})\")\n",
    "        where_clause = \" AND \".join(filter_conditions)\n",
    "        if where_clause:\n",
    "            filter_sql = base_sql_query + \" WHERE \" + where_clause\n",
    "    elif needs == 'Delivery Options':\n",
    "        pass \n",
    "    elif needs == 'Find Similar':\n",
    "        product_requirement = execute_purchase(dialogue_state)\n",
    "        product_chosen = getProduct(product_requirement, dialogue_state)\n",
    "        # temporarily, it will search product as a statistic of products be chosen \n",
    "        # get cpu, gpu, screen_resolution, ram\n",
    "\n",
    "        cpu_require = product_chosen[0]['cpu']\n",
    "        gpu_require = product_chosen[0]['gpu']\n",
    "        screen_need = product_chosen[0]['screen_resolution']\n",
    "        ram = product_chosen[0]['ram']\n",
    "        filter_sql = f\"SELECT laptop.id, brand, prod_name, ram, cpu, gpu, screen_resolution, cpu_info.score AS cpu_score, gpu_info.score AS gpu_score, screen_resolution_info.score AS screen_score, battery, price_range, screen_size, screen_fresh_rate, os, battery_capacity, weight from laptop join cpu_info using (cpu_id) join gpu_info using (gpu_id) join screen_resolution_info USING (screen_id) WHERE ram = {ram} AND cpu = '{cpu_require}' AND gpu = '{gpu_require}' AND screen_resolution = '{screen_need}'\"\n",
    "\n",
    "    else:\n",
    "        product_requirement = execute_purchase(dialogue_state)\n",
    "        print(product_requirement)\n",
    "        product_chosen = getProduct(product_requirement, dialogue_state)\n",
    "        cur_position = dialogue_state['positional_product']\n",
    "        if cur_position != -10:\n",
    "            product = getProductFromFilter(product_chosen, cur_position)\n",
    "        else:\n",
    "            product = product_chosen[0] # only has one product suit with user requirement\n",
    "        if needs == 'Purchase Decision':\n",
    "            filter_sql = f\"INSERT INTO orders(id) VALUES({product['id']})\"\n",
    "    return filter_sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "def execute_sql_query(query, fetch_results = False):\n",
    "    conn_params = {\n",
    "        \"host\": \"localhost\",\n",
    "        \"dbname\": 'Graduation_Research_1',\n",
    "        \"user\": 'postgres',\n",
    "        \"password\": '03082004'\n",
    "    }\n",
    "    products = []\n",
    "    try:\n",
    "        connection = psycopg2.connect(**conn_params)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        #print(fetch_results)\n",
    "        if fetch_results:\n",
    "            res = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            for row in res:\n",
    "                product = dict(zip(columns, row))\n",
    "                products.append(product)\n",
    "        else:\n",
    "            connection.commit()\n",
    "            #print(\"Here\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection:\n",
    "            connection.close()\n",
    "    return products if fetch_results else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weight(weights):\n",
    "    for key in weights:\n",
    "        weights[key] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_performance(score):\n",
    "    if score >= 7.5:\n",
    "        print(\"Sản phẩm này có thể đáp ứng rất tốt cho nhu cầu của bạn\")\n",
    "    elif score >= 6.5:\n",
    "        print(\"Sản phẩm này có thể đáp ứng ổn cho nhu cầu của bạn\")\n",
    "    elif score >= 5.5:\n",
    "        print(\"Sản phẩm này có thể đáp ứng nhu cầu của bạn một cách trung bình\")\n",
    "    else:\n",
    "        print(\"Rất tiếc, thông số của sản phẩm này không đủ để đáp ứng nhu cầu của bạn, bạn nên tìm hiểu những mấu khác\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current state of dialogue_state\n",
    "def print_dialogue_state(dialogue_state):\n",
    "    if dialogue_state['intent'] is not None:\n",
    "        print(f\"Intent: {dialogue_state['intent']}\")\n",
    "    \n",
    "    print(\"\\nProduct Specifications:\")\n",
    "    for key, value in dialogue_state['entities_in_conversation'].items():\n",
    "        if key not in dialogue_state['entities_for_specific_need']:  \n",
    "            if value[\"values\"]:  \n",
    "                value_str = ', '.join(map(str, value['values']))\n",
    "                print(f\"{key.capitalize().replace('_', ' ')}: {value_str}\")\n",
    "            if value[\"selected\"]:  \n",
    "                print(f\"Selected {key.capitalize().replace('_', ' ')}: {value['selected']}\")\n",
    "    \n",
    "    print(\"\\nSpecific Needs:\")\n",
    "    for key, value in dialogue_state['entities_for_specific_need'].items():\n",
    "        if value:  # Check if the specific need is True\n",
    "            print(f\"  {key.capitalize().replace('_', ' ')}: {value}\")\n",
    "\n",
    "def printProduct(dialogue_state):\n",
    "    print(\"\\nList of Products: \")\n",
    "    i = 1\n",
    "    for product in dialogue_state['product_in_current_message']:\n",
    "        print(f\"Product {i}:\")\n",
    "        for key, value in product.items():\n",
    "            if dialogue_state['intent'] == 'Price Inquiry':\n",
    "                if key in ['prod_name', 'price_range']:\n",
    "                    print(f\"{key}: {value}\")\n",
    "            else:\n",
    "                if key not in ['cpu_score', 'gpu_score', 'screen_resolution_score', 'evaluate_score', 'id']: # this stat do not need to show\n",
    "                    print(f\"{key}: {value}\")\n",
    "        print(\"__________________________________________________________\")\n",
    "        i+= 1\n",
    "\n",
    "def update_dialogue_state(user_input, dialogue_state, id_to_label, num_to_label):\n",
    "    tmp_product = [] # used to store temporaly the products before evaluated\n",
    "    # Predict intent and update dialogue state\n",
    "    predicted_intent = predict_intent(model_intent, tokenizer_intent, user_input, tfidf_vectorizer)\n",
    "    dialogue_state['intent'] = predicted_intent\n",
    "    \n",
    "    # Predict entities and update dialogue state\n",
    "    entities = predict_ner(user_input, ner_pipe, id_to_label)\n",
    "    \n",
    "    for entity, label in entities:\n",
    "        if label == \"price_range\":\n",
    "            entity = convert_trieu_to_number(entity)\n",
    "            entity = float(entity)        \n",
    "        if label in dialogue_state['entities_in_conversation']:\n",
    "            if label in ['ram', 'screen_size', 'battery_capacity', 'weight', 'screen_fresh_rate']:\n",
    "                entity = float(entity)\n",
    "            if not any(entity == existing for existing in dialogue_state['entities_in_conversation'][label][\"values\"]):\n",
    "                dialogue_state['entities_in_conversation'][label][\"values\"].append(entity)\n",
    "            if predicted_intent in [\"Change Decision\", \"Interest Confirmation\", \"Product Availability\", \"Purchase Decision\", \"Feature Confirmation\", \"Price Inquiry\", \"Find Similar\"]:\n",
    "                dialogue_state['entities_in_conversation'][label][\"selected\"] = entity\n",
    "    \n",
    "        elif label in dialogue_state['entities_for_specific_need']:\n",
    "            dialogue_state['entities_for_specific_need'][label] = True\n",
    "\n",
    "    print(\"Updated Dialogue State:\")\n",
    "    print_dialogue_state(dialogue_state)\n",
    "    if predicted_intent not in ['Feature Confirmation', 'Thank You/Closing', 'Payment Option', 'Return Policy Inquiry']:\n",
    "        if predicted_intent != 'Interest Confirmation':\n",
    "            filter_sql = generating_sql(dialogue_state)\n",
    "            if filter_sql:\n",
    "                print(\"Generated SQL Query:\")\n",
    "                print(filter_sql)\n",
    "                if predicted_intent != 'Purchase Decision':\n",
    "                    product_retrieve = execute_sql_query(filter_sql, fetch_results=True)\n",
    "                    for product_data in product_retrieve:\n",
    "                        product = {\n",
    "                            \"id\": product_data.get(\"id\"),\n",
    "                            \"prod_name\": product_data.get(\"prod_name\"),\n",
    "                            \"brand\": product_data.get(\"brand\"), \n",
    "                            \"cpu\": product_data.get(\"cpu\"), \n",
    "                            \"gpu\": product_data.get(\"gpu\"),\n",
    "                            \"ram\": product_data.get(\"ram\"), #\n",
    "                            \"battery\": product_data.get(\"battery\"), #\n",
    "                            \"price_range\": product_data.get(\"price_range\"),\n",
    "                            \"screen_size\": product_data.get(\"screen_size\"),\n",
    "                            \"screen_resolution\": product_data.get(\"screen_resolution\"),\n",
    "                            \"screen_fresh_rate\": product_data.get(\"screen_fresh_rate\"), #\n",
    "                            \"os\": product_data.get(\"os\"), \n",
    "                            \"battery_capacity\": product_data.get(\"battery_capacity\"),\n",
    "                            \"weight\": product_data.get(\"weight\"), #\n",
    "                            \"cpu_score\": product_data.get(\"cpu_score\"), # it will not be printed, used for evaluating\n",
    "                            \"gpu_score\": product_data.get(\"gpu_score\"), # used for evaluating\n",
    "                            \"screen_resolution_score\": product_data.get(\"screen_score\"), # used to evaluate\n",
    "                            \"evaluate_score\": None\n",
    "                        }    \n",
    "                        #print(product)\n",
    "                        tmp_product.append(product)\n",
    "                    if predicted_intent == 'Price Inquiry':\n",
    "                        dialogue_state['product_in_current_message'] = tmp_product\n",
    "                        for product in tmp_product:\n",
    "                            if product['id'] not in dialogue_state['product_in_conversation']:\n",
    "                                dialogue_state['product_in_conversation'].append(product)\n",
    "                        printProduct(dialogue_state)\n",
    "                    else:\n",
    "                        updateWeight(dialogue_state) # update only one time before doing anything\n",
    "                        for product in tmp_product:\n",
    "                            product['evaluate_score'] = evaluate(dialogue_state,product)\n",
    "                        top_products = sorted(tmp_product, key=lambda x: x['evaluate_score'], reverse=True)[:5]\n",
    "                        for product in top_products:\n",
    "                            dialogue_state['product_in_current_message'].append(product)\n",
    "                            if product['id'] not in dialogue_state['product_in_conversation']: # to avoid the same product be assigned to my list\n",
    "                                dialogue_state['product_in_conversation'].append(product)\n",
    "                        reset_weight(weights)\n",
    "                        printProduct(dialogue_state)\n",
    "                    dialogue_state['product_in_current_message'] = []\n",
    "                else: # Purchase Confirmation\n",
    "                    # check for user input, just only 1 position\n",
    "                    dialogue_state['positional_product'] = extract_positional_phrases_vietnamese(user_input) \n",
    "                    execute_sql_query(filter_sql, fetch_results=False)\n",
    "                    print(\"Complete Updated Orders\")   \n",
    "        else: # = interest confirmation\n",
    "            feature = execute_purchase(dialogue_state)\n",
    "            #print(f\"Here is feature: {feature}\")\n",
    "            product_chosen = getProduct(feature, dialogue_state) # array\n",
    "            #print(product_chosen)\n",
    "            #print(f\"Product chosen: {product_chosen}\")\n",
    "            if len(product_chosen) != 0: # existed product, do not search more\n",
    "                # check for position\n",
    "                dialogue_state['positional_product'] = extract_positional_phrases_vietnamese(user_input)\n",
    "                cur_position = dialogue_state['positional_product']\n",
    "                if cur_position != -10: # existed position\n",
    "                    product_need = getProductFromFilter(product_chosen, cur_position)\n",
    "                    dialogue_state['product_in_current_message'].append(product_need)\n",
    "                else: \n",
    "                    for prod in product_chosen:\n",
    "                        dialogue_state['product_in_current_message'].append(prod)\n",
    "                printProduct(dialogue_state)\n",
    "                dialogue_state['product_in_current_message'] = [] # reset\n",
    "            else: \n",
    "                filter_sql = generating_sql(dialogue_state)\n",
    "                if filter_sql:\n",
    "                    tmp_product = []\n",
    "                    product_get = execute_sql_query(filter_sql, fetch_results=True)\n",
    "                    for product_data in product_get:\n",
    "                        product = {\n",
    "                            \"id\": product_data.get(\"id\"),\n",
    "                            \"prod_name\": product_data.get(\"prod_name\"),\n",
    "                            \"brand\": product_data.get(\"brand\"), \n",
    "                            \"cpu\": product_data.get(\"cpu\"), \n",
    "                            \"gpu\": product_data.get(\"gpu\"),\n",
    "                            \"ram\": product_data.get(\"ram\"), #\n",
    "                            \"battery\": product_data.get(\"battery\"), #\n",
    "                            \"price_range\": product_data.get(\"price_range\"),\n",
    "                            \"screen_size\": product_data.get(\"screen_size\"),\n",
    "                            \"screen_resolution\": product_data.get(\"screen_resolution\"),\n",
    "                            \"screen_fresh_rate\": product_data.get(\"screen_fresh_rate\"), #\n",
    "                            \"os\": product_data.get(\"os\"), \n",
    "                            \"battery_capacity\": product_data.get(\"battery_capacity\"),\n",
    "                            \"weight\": product_data.get(\"weight\"), #\n",
    "                            \"cpu_score\": product_data.get(\"cpu_score\"), # it will not be printed, used for evaluating\n",
    "                            \"gpu_score\": product_data.get(\"gpu_score\"), # used for evaluating\n",
    "                            \"screen_resolution_score\": product_data.get(\"screen_score\"), # used to evaluate\n",
    "                            \"evaluate_score\": None\n",
    "                        }    \n",
    "                        tmp_product.append(product)\n",
    "            \n",
    "                    updateWeight(dialogue_state)\n",
    "                    for product in tmp_product:\n",
    "                        product['evaluate_score'] = evaluate(dialogue_state, product)\n",
    "                    top_products = sorted(tmp_product, key=lambda x: x['evaluate_score'], reverse=True)[:5]\n",
    "                    for product in top_products:\n",
    "                        dialogue_state['product_in_current_message'].append(product)\n",
    "                        if product['id'] not in dialogue_state['product_in_conversation']:\n",
    "                            dialogue_state['product_in_conversation'].append(product)\n",
    "                    reset_weight(weights)\n",
    "                    printProduct(dialogue_state)     \n",
    "                    dialogue_state['product_in_current_message'] = [] # reset the state for the next message  \n",
    "\n",
    "    elif predicted_intent == 'Return Policy Inquiry':\n",
    "        refund_rate = 70\n",
    "        print(\n",
    "            f\"Với mọi sản phẩm của chúng tôi, quý khách có thể trải nghiệm và trả lại nếu cảm thấy không phù hợp mà không mất phí trong vòng 7 ngày đầu, \"\n",
    "            f\"và nhận lại {refund_rate}% số tiền trong vòng 1 tháng nếu quý khách muốn đổi trả. Sau 30 ngày, chúng tôi không nhận bất cứ yêu cầu đổi trả nào, \"\n",
    "            f\"mà sẽ mua lại tùy theo tình trạng của sản phẩm.\"   \n",
    "        )\n",
    "    elif predicted_intent == 'Feature Confirmation':\n",
    "        product_requirement = execute_purchase(dialogue_state)\n",
    "        print(product_requirement)\n",
    "        product_chosen = getProduct(product_requirement, dialogue_state)\n",
    "        dialogue_state['positional_product'] = extract_positional_phrases_vietnamese(user_input)\n",
    "        cur_position = dialogue_state['positional_product']\n",
    "        if cur_position != -10:\n",
    "            product_need = getProductFromFilter(product_chosen, cur_position)\n",
    "        else:\n",
    "            product_need = product_chosen[0]\n",
    "        #print(product_chosen)\n",
    "        dialogue_state['product_in_current_message'].append(product_need)\n",
    "        printProduct(dialogue_state)\n",
    "        dialogue_state['product_in_current_message'] = []\n",
    "        updateWeight(dialogue_state) # update each time perform calculating\n",
    "        product_chosen['evaluate_score'] = evaluate(dialogue_state, product_chosen)\n",
    "        #print(weights)\n",
    "        #print(product_chosen['evaluate_score'])\n",
    "        reset_weight(weights)\n",
    "        check_for_performance(product_chosen['evaluate_score'])\n",
    "    dialogue_state['positional_product'] = -10 # reset\n",
    "\n",
    "            \n",
    "    \n",
    "# Reset the dialogue state for a new conversation\n",
    "def reset_dialogue_state(dialogue_state):\n",
    "    dialogue_state[\"intent\"] = None\n",
    "    for key in dialogue_state[\"entities_in_conversation\"]:\n",
    "        dialogue_state[\"entities_in_conversation\"][key][\"values\"] = []\n",
    "        dialogue_state[\"entities_in_conversation\"][key][\"selected\"] = None\n",
    "    for key in dialogue_state[\"entities_for_specific_need\"]:\n",
    "        dialogue_state[\"entities_for_specific_need\"][key] = False\n",
    "    dialogue_state['product_in_conversation'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Tôi cần tìm laptop khoảng 25 triệu để chơi game và làm về đồ họa \n",
      "Updated Dialogue State:\n",
      "Intent: Specific Need\n",
      "\n",
      "Product Specifications:\n",
      "Price range: 25000000.0\n",
      "\n",
      "Specific Needs:\n",
      "  Game task: True\n",
      "Generated SQL Query:\n",
      "\n",
      "    SELECT laptop.id, brand, prod_name, ram, cpu, gpu, screen_resolution, \n",
      "           cpu_info.score AS cpu_score, gpu_info.score AS gpu_score, \n",
      "           screen_resolution_info.score AS screen_score, battery, price_range, \n",
      "           screen_size, screen_fresh_rate, os, battery_capacity, weight \n",
      "    FROM laptop \n",
      "    JOIN cpu_info USING (cpu_id) \n",
      "    JOIN gpu_info USING (gpu_id) \n",
      "    JOIN screen_resolution_info USING (screen_id)\n",
      "     WHERE (price_range <= 25000000.0)\n",
      "\n",
      "List of Products: \n",
      "Product 1:\n",
      "prod_name: Laptop Asus TUF Gaming A16 FA617NSR (RL100W)\n",
      "brand: Asus\n",
      "cpu: AMD Ryzen 7 - 7435HS\n",
      "gpu: AMD Radeon RX 7600S, 8 GB\n",
      "ram: 16\n",
      "battery: 4\n",
      "price_range: 24990000.0\n",
      "screen_size: 16.0\n",
      "screen_resolution: WUXGA\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 240\n",
      "weight: 2.2\n",
      "__________________________________________________________\n",
      "Product 2:\n",
      "prod_name: Laptop Acer Nitro AN515 58 773Y (NH.QFKSV.001.16G)\n",
      "brand: Acer\n",
      "cpu: Intel Core i7 Alder Lake - 12700H\n",
      "gpu: NVIDIA GeForce RTX 3050Ti, 4 GB\n",
      "ram: 16\n",
      "battery: 4\n",
      "price_range: 23490000.0\n",
      "screen_size: 15.6\n",
      "screen_resolution: Full HD\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 180\n",
      "weight: 2.5\n",
      "__________________________________________________________\n",
      "Product 3:\n",
      "prod_name: Laptop MSI Cyborg 15 A13VEK (1423VN)\n",
      "brand: MSI\n",
      "cpu: Intel Core i7 Raptor Lake - 13620H\n",
      "gpu: NVIDIA GeForce RTX 4050, 6 GB\n",
      "ram: 16\n",
      "battery: 3\n",
      "price_range: 24990000.0\n",
      "screen_size: 15.6\n",
      "screen_resolution: Full HD\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 120\n",
      "weight: 1.98\n",
      "__________________________________________________________\n",
      "Product 4:\n",
      "prod_name: Laptop Acer Nitro V ANV15 51 75GS (NH.QN8SV.005)\n",
      "brand: Acer\n",
      "cpu: Intel Core i7 Raptor Lake - 13620H\n",
      "gpu: NVIDIA GeForce RTX 4050, 6 GB\n",
      "ram: 16\n",
      "battery: 4\n",
      "price_range: 23990000.0\n",
      "screen_size: 15.6\n",
      "screen_resolution: Full HD\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 135\n",
      "weight: 2.1\n",
      "__________________________________________________________\n",
      "Product 5:\n",
      "prod_name: Laptop Acer Gaming Nitro 5 Tiger AN515 58 773Y (NH.QFKSV.001)\n",
      "brand: Acer\n",
      "cpu: Intel Core i7 Alder Lake - 12700H\n",
      "gpu: NVIDIA GeForce RTX 3050Ti, 4 GB\n",
      "ram: 8\n",
      "battery: 4\n",
      "price_range: 22490000.0\n",
      "screen_size: 15.6\n",
      "screen_resolution: Full HD\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 180\n",
      "weight: 2.5\n",
      "__________________________________________________________\n",
      "User: Con Acer cuối cùng này có hỗ trợ huấn luyện mô hình AI không\n",
      "Updated Dialogue State:\n",
      "Intent: Feature Confirmation\n",
      "\n",
      "Product Specifications:\n",
      "Brand: acer\n",
      "Selected Brand: acer\n",
      "Price range: 25000000.0\n",
      "\n",
      "Specific Needs:\n",
      "  Game task: True\n",
      "  Ai task: True\n",
      "{'brand': 'acer'}\n",
      "\n",
      "List of Products: \n",
      "Product 1:\n",
      "prod_name: Laptop Acer Gaming Nitro 5 Tiger AN515 58 773Y (NH.QFKSV.001)\n",
      "brand: Acer\n",
      "cpu: Intel Core i7 Alder Lake - 12700H\n",
      "gpu: NVIDIA GeForce RTX 3050Ti, 4 GB\n",
      "ram: 8\n",
      "battery: 4\n",
      "price_range: 22490000.0\n",
      "screen_size: 15.6\n",
      "screen_resolution: Full HD\n",
      "screen_fresh_rate: 144\n",
      "os: Windows 11 Home SL\n",
      "battery_capacity: 180\n",
      "weight: 2.5\n",
      "__________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     reset_weight(weights)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mupdate_dialogue_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialogue_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_to_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_label\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[27], line 195\u001b[0m, in \u001b[0;36mupdate_dialogue_state\u001b[1;34m(user_input, dialogue_state, id_to_label, num_to_label)\u001b[0m\n\u001b[0;32m    193\u001b[0m dialogue_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_in_current_message\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    194\u001b[0m updateWeight(dialogue_state) \u001b[38;5;66;03m# update each time perform calculating\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m product_chosen[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_chosen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m#print(weights)\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m#print(product_chosen['evaluate_score'])\u001b[39;00m\n\u001b[0;32m    198\u001b[0m reset_weight(weights)\n",
      "Cell \u001b[1;32mIn[16], line 67\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dialogue_state, product)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# formula = sum(weights['type'] * product['type'])\u001b[39;00m\n\u001b[0;32m     66\u001b[0m user_needs \u001b[38;5;241m=\u001b[39m dialogue_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentities_for_specific_need\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 67\u001b[0m normalize_product \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m normalize_product:\n\u001b[0;32m     69\u001b[0m     cur_point \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m weights[label] \u001b[38;5;241m*\u001b[39m normalize_product[label]             \n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(product)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(product):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Normalizing individual attributes with checks for None values\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     normalize_ram_point \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.07\u001b[39m \u001b[38;5;241m*\u001b[39m (product[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mram\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8\u001b[39m)))\n\u001b[1;32m----> 7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mram\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     normalize_screen_fresh_rate \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.04\u001b[39m \u001b[38;5;241m*\u001b[39m (product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_fresh_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m96.22\u001b[39m)))\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_fresh_rate\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# Default to 60 Hz\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     15\u001b[0m     normalize_battery \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.38\u001b[39m \u001b[38;5;241m*\u001b[39m (product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbattery\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m product\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbattery\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "list_quit = ['bye', 'quit']\n",
    "while(1):\n",
    "    user_input = input(\"User: \")\n",
    "    print(f\"User: {user_input}\")\n",
    "    if(user_input.lower() in list_quit):\n",
    "        print('Bye')\n",
    "        reset_dialogue_state(dialogue_state)\n",
    "        reset_weight(weights)\n",
    "        break\n",
    "    update_dialogue_state(user_input, dialogue_state, id_to_label, num_to_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "-1\n",
      "2\n",
      "-10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_positional_phrases_vietnamese(text):\n",
    "    positional_keywords = {\n",
    "        \"đầu tiên\": 0,\n",
    "        \"đầu\": 0,\n",
    "        \"cuối\": -1,\n",
    "        \"cuối cùng\": -1,\n",
    "        \"sau cùng\": -1,\n",
    "        \"vừa được\": -1,\n",
    "        \"mới được\": -1,\n",
    "        \"vừa rồi\": -1,\n",
    "        \"thứ nhất\": 0,\n",
    "        \"thứ hai\": 1\n",
    "    }\n",
    "\n",
    "    regex = r'\\b(đầu tiên|đầu|cuối cùng|sau cùng|cuối|vừa được|mới được|vừa rồi|thứ nhất|thứ hai|thứ (\\d+))\\b'\n",
    "    match = re.search(regex, text.lower(), re.UNICODE)\n",
    "\n",
    "    if match:\n",
    "        matched_word = match.group(1)  \n",
    "        if \"thứ\" in matched_word:\n",
    "            if matched_word in positional_keywords:\n",
    "                return positional_keywords[matched_word]  \n",
    "            else:\n",
    "                number = int(match.group(2))  \n",
    "                return number - 1\n",
    "        else:\n",
    "            return positional_keywords[matched_word]\n",
    "    else:\n",
    "        return -10  # Default value for no match\n",
    "\n",
    "# Example usage\n",
    "print(extract_positional_phrases_vietnamese(\"đây là sản phẩm thứ nhất\"))  # Output: 0\n",
    "print(extract_positional_phrases_vietnamese(\"đây là sản phẩm thứ hai\"))   # Output: 1\n",
    "print(extract_positional_phrases_vietnamese(\"sản phẩm cuối cùng\"))        # Output: -1\n",
    "print(extract_positional_phrases_vietnamese(\"sản phẩm thứ 3\"))            # Output: 2\n",
    "print(extract_positional_phrases_vietnamese(\"không có gì phù hợp\"))       # Output: -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
